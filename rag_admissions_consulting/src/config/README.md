# Backend Config Loading

Há»‡ thá»‘ng RAG há»— trá»£ load config tá»« backend NestJS Ä‘á»ƒ Ä‘á»“ng bá»™ cáº¥u hÃ¬nh.

## ğŸ”§ CÃ¡ch hoáº¡t Ä‘á»™ng

1. **Khi khá»Ÿi Ä‘á»™ng app**: RAG system sáº½ gá»i API `GET /v1/chatbot-config/rag/config` Ä‘á»ƒ láº¥y config
2. **Merge config**: Chá»‰ update nhá»¯ng field cÃ³ giÃ¡ trá»‹ tá»« backend, cÃ²n láº¡i giá»¯ nguyÃªn config local
3. **Fallback**: Náº¿u backend khÃ´ng available, sáº½ sá»­ dá»¥ng config local

## ğŸ“¡ API Endpoint

```
GET http://localhost:5000/api/v1/chatbot-config/rag/config
```

**Response format:**
```json
{
  "llmConfig": {
    "defaultModel": "GEMINI",
    "maxTokens": 2048,
    "temperature": 0.7
  },
  "chatConfig": {
    "maxContextLength": 20,
    "contextWindowMinutes": 30,
    "maxResponseTokens": 1024,
    "streamDelayMs": 50
  },
  "personality": {
    "name": "Assistant",
    "persona": "Báº¡n lÃ  má»™t chuyÃªn viÃªn tÆ° váº¥n...",
    "personality": "Professional",
    "creativityLevel": 0.2
  },
  "contactInfo": {
    "hotline": "0236.3.650.403",
    "email": "tuyensinh@donga.edu.vn",
    "website": "https://donga.edu.vn",
    "address": "33 XÃ´ Viáº¿t Nghá»‡ TÄ©nh, Háº£i ChÃ¢u, ÄÃ  Náºµng"
  },
  "environment": "development",
  "debug": false
}
```

## âš™ï¸ Environment Variables

```bash
# CÃ³ load config tá»« backend khÃ´ng
USE_BACKEND_CONFIG=true

# URL cá»§a backend server (bao gá»“m /api/v1)
BACKEND_URL=http://localhost:5000/api/v1
```

## ğŸš€ CÃ¡ch sá»­ dá»¥ng

### 1. Async Loading (trong startup)
```python
from config.settings import settings

# Load config khi khá»Ÿi Ä‘á»™ng app
success = await settings.load_config_from_backend()
if success:
    print("âœ… Config loaded from backend")
else:
    print("âš ï¸ Using local config")
```

### 2. Sync Loading
```python
from config.settings import settings

# Load config sync
success = settings.load_config_from_backend_sync()
```

### 3. Access config
```python
from config.settings import settings

# LLM config
model = settings.llm.default_model
max_tokens = settings.llm.max_tokens
temperature = settings.llm.temperature

# Chat config
context_length = settings.chat.max_context_length

# Personality
assistant_name = settings.get_assistant_name()
persona = settings.get_persona_for_prompt()

# Contact info
hotline = settings.contact_info["hotline"]
email = settings.contact_info["email"]
```

## ğŸ§ª Testing

```bash
# Test config loading
cd src/config
python test_config.py
```

**Expected output:**
```
ğŸ§ª Testing environment variables...
ğŸ§ª Testing backend config loading...
âœ… Successfully fetched config from backend!
âœ… Successfully applied backend config!
ğŸ‰ Test completed!
```

## ğŸ”„ Config Priority

1. **Backend config** (highest priority)
2. **Local environment variables**
3. **Default values** (lowest priority)

## ğŸ›¡ï¸ Error Handling

- Timeout: 10 giÃ¢y
- HTTP errors: Log vÃ  fallback vá» local config
- Network errors: Log vÃ  fallback vá» local config
- Parse errors: Log vÃ  fallback vá» local config

## ğŸ“ Notes

- Config tá»« backend chá»‰ update nhá»¯ng field cÃ³ giÃ¡ trá»‹
- Personality vÃ  contact info Ä‘Æ°á»£c merge tá»« backend
- API keys khÃ´ng Ä‘Æ°á»£c láº¥y tá»« backend (báº£o máº­t)
- Debug mode vÃ  environment Ä‘Æ°á»£c sync tá»« backend 