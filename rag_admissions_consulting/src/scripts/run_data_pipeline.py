#!/usr/bin/env python3
"""
Data Pipeline Runner
Ch·∫°y to√†n b·ªô pipeline t·ª´ crawling ƒë·∫øn processing
"""

import subprocess
import sys
import time
import os
from datetime import datetime
from loguru import logger


def run_command(command, description):
    """Ch·∫°y m·ªôt command v√† log k·∫øt qu·∫£"""
    logger.info(f"üöÄ {description}")
    logger.info(f"üìù Command: {command}")

    try:
        result = subprocess.run(
            command,
            shell=True,
            capture_output=True,
            text=True,
            cwd=os.path.dirname(os.path.abspath(__file__)),
        )

        if result.returncode == 0:
            logger.success(f"‚úÖ {description} - COMPLETED")
            if result.stdout:
                logger.info(f"Output: {result.stdout[:200]}...")
        else:
            logger.error(f"‚ùå {description} - FAILED")
            logger.error(f"Error: {result.stderr}")
            return False

    except Exception as e:
        logger.error(f"‚ùå {description} - ERROR: {e}")
        return False

    return True


def main():
    """Ch·∫°y to√†n b·ªô data pipeline"""
    start_time = datetime.now()

    logger.info("üéØ RAG Admissions Consulting - Data Pipeline")
    logger.info(f"‚è∞ Started at: {start_time}")
    logger.info("=" * 60)

    # Pipeline steps
    steps = [
        {
            "command": "python data_pipeline/crawlers/scraper.py",
            "description": "Web Crawling - Thu th·∫≠p d·ªØ li·ªáu t·ª´ website",
        },
        {
            "command": "python data_pipeline/processors/data_processing.py",
            "description": "Data Processing - X·ª≠ l√Ω v√† l√†m s·∫°ch d·ªØ li·ªáu",
        },
        {
            "command": "python scripts/seed.py",
            "description": "Vector Store Seeding - C·∫≠p nh·∫≠t vector database",
        },
    ]

    success_count = 0
    total_steps = len(steps)

    for i, step in enumerate(steps, 1):
        logger.info(f"\nüìä Step {i}/{total_steps}")

        if run_command(step["command"], step["description"]):
            success_count += 1
        else:
            logger.warning(f"‚ö†Ô∏è Step {i} failed, continuing with next step...")

        # ƒê·ª£i gi·ªØa c√°c b∆∞·ªõc
        if i < total_steps:
            time.sleep(2)

    # T·ªïng k·∫øt
    end_time = datetime.now()
    duration = end_time - start_time

    logger.info("\n" + "=" * 60)
    logger.info("üéâ DATA PIPELINE SUMMARY")
    logger.info("=" * 60)
    logger.info(f"‚è∞ Started: {start_time}")
    logger.info(f"‚è∞ Finished: {end_time}")
    logger.info(f"‚è±Ô∏è Duration: {duration}")
    logger.info(f"‚úÖ Successful steps: {success_count}/{total_steps}")
    logger.info(f"‚ùå Failed steps: {total_steps - success_count}/{total_steps}")

    if success_count == total_steps:
        logger.success("üéä ALL STEPS COMPLETED SUCCESSFULLY!")
        logger.info("üìä Data pipeline finished. RAG system is ready!")
    else:
        logger.warning("‚ö†Ô∏è Some steps failed. Check logs for details.")
        logger.info("üí° You can run individual steps manually if needed.")

    return success_count == total_steps


if __name__ == "__main__":
    # Configure logging
    logger.remove()
    logger.add(
        sys.stderr,
        level="INFO",
        format="{time:YYYY-MM-DD HH:mm:ss} | {level} | {message}",
    )
    logger.add(
        "logs/data_pipeline_{time:YYYY-MM-DD}.log",
        level="DEBUG",
        format="{time:YYYY-MM-DD HH:mm:ss} | {level} | {message}",
        rotation="1 day",
    )

    success = main()
    sys.exit(0 if success else 1)
